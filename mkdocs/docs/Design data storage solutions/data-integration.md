# Design data integration

## Azure data factory
ETL (Extract - Transform - Load)

 1. Connect and collect
 2. Transform and enrich (using Azure databricks, Azure HDInsight Hadoop)
 3. CI/CD and publish
 4. Monitor

Consider :
 - Requirements
 - Coding resources: Azure data factory provide low/no code.
 - Support for multiple data sources: 90+ connectors.
 - Serverless infrastructure

## Azure data lake
Repository of data
Can store any typr of dta.
Designed to work with Hadoop (HDFS)
High troughput for input and output intense analytic and data movement.
RBAC and ACL

1. Ingest data
- Unplanned data: AzCopy, Azure CLI, powersheel, Azure storage explorer
- Relational data: Azure data factory can bu used.
- Streaming data: Apachage Storm on Azure HDInsight, Azure Stream analytic.
2. Access stored data : Azure storage explorer but any way to reach Azure blob storage would work
3. Configure access control : RBAC or ACL

| Compare | Azure data lake | Azure blob storage |
|--|--|--|
| Data types | Large volumes of text data | Unstructure non-text based data (videos, ...) |
| Geographic redundancy | Manually configure data replication | Provide geo redundant storage by default |
| Namespace | Hierarchical namespace | Flat namespace |
| Hadoop compatibility | Yes | By using Azure blob filesystem driver |
| Security | Support granular access | Granular access isn't supported |

## Azure databricks
Big data and machine learning platform.
Based on Apache Spark.
Can be used with SQL/Java/Python/R/Scala.

Control plane: Host jobs, notebooks with query result and cluster manager.
Data plane: Runtime cluster hosted within the workspace.
3 environements :
- Databricks SQL: Platform for analyst to run SQL on data lake. Build and share dashboard.
- Databricks Data science & engineering: Interactive workspace that enable collaboration between engineeers. For big data pipeline can use Azure Data Factory or Apache Kafka/Azure Event Hubs/Azure IOT hub.
- Databricks machine learning: integrated end to end machine learning environment.
-
## Azure synapse analytics
Big data analytic, enterprise data storage and data integration.
Composed of a control node and compute nodes.
Use Polybase.

Azure Synapse SQL pool : serverless and dedicated resource.
Azure Synapse Spark pool : Cluster that run ApacheSpark to process data.
Azure Synapse Pipeline: Applies the capability of Azure Data Factory.
Azure Synapse Link: Connect to Azure Cosmos DB for near real time analytic.
Azure Synapse Studio: Web based IDE.

Analytical options :
- Descriptive: What is happening
- Diagnostic: Why is it happening
- Preditive: What is likely to happen
- Prescriptive: What needs to be done

| Compare | Azure data factory | Azure synapse analytics |
|--|--|--|
| Data sharing | Data can be shared across different data factories | Not supported |
| Solution templates | Solution templates are provided with the Azure Data Factory template gallery | Solution templates are provided in the Synapse Workspace Knowledge center |
| Integration runtime cross region flows | Cross region data flows are supported | Not supported |
| Monitor data | Data monitoring is integrated with Azure Monitor | Diagnostic logs are available in Azure Monitor |
| Monitor Spark Jobs for data flow | Not supported | Spark Jobs can be monitored for data flow by using Synapse Spark pools |

## Hot, warm and cold data paths

Warm data path supports analyzing as it flow through the system. Near real time. Azure stream analytics.

Cold data path discover patterns over time.

Hot data path used for processing/displaying data in real time. Employed for real-time alerting. Low latency.

## Azure stream analytics

Data stream : Continuous data generated by applications.
Event processing: Consumption and analysis of a continuous data stream.
Support events in 3 formats : CSV, JSON, Avro

Stream analytics ingest data from Azure event hubs, Azure IOT hub or Azure blob storage.
The query (based on SQL) can filter/sort/aggregate and join streaming data.
Query can be extended with JS and C# UDF.
